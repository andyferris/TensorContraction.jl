# Tensors.jl

[![Build Status](https://travis-ci.org/andyferris/TensorContraction.jl.svg?branch=master)](https://travis-ci.org/andyferris/TensorContraction.jl)

A Julia language package for implementing simple tensor operations in a user-friendly manner. A tensor is a decorated multi-dimensional array, with a name attached to each index. In a tensor contraction (generalized matrix multiplication), contracted indices are automatically matched.

A simple example is:

```julia
x::Array{Float64,2}
A::Array{Float64,2}
@tensor y[[a]] = A[[a,b]] * x[[b]]
```

This implements matrix-vector multiplication, resulting in a vector `y` associated with the vector space labelled by `a` above. 

### Features

1. Tensors can also be de-indexed in the desired order, on either side of the equality:

```julia
@tensor M = (rand(4,4))[[a,b]] # a rank-2 tensor
@tensor M[[b,a]] # the transpose of M (an Array)
@tensor M2[[b,a]] = M # M2 must already be of type Array{T,2}
```

2. `Tensor`'s that have not been deindexed remain as `Tensor` objects, but can be treated as arrays. Operations such as `+` will automatically take care of the necessary permutations. Several common element-wise operations like `exp`, `log`, `sin`, `cos` are defined.

3. `eig` and `svd` have been defined for tensors. Use, e.g., `svd(tensor,LeftIndices::Tuple,RightIndices::Tuple)` to generate the SVD of the tensor where the matrix form is interpreted as `LeftIndices` by `RightIndices`, and the output are appropriately labelled tensors.


### How it works

The package relies heavily on Julia's expressive type system. The index names are embedded as either bitstype values (e.g. integers) or  `Symbol` *values* like `Val{:a}` and are a part of the tensor's parametric type.

In this way, appropriate code is generated by `*`, `getindex` and `setindex!` at *compile time* and the operations run at full-speed at *run time*. 

The `@tensor` macro is for convenience, mangling the expression so that ``[[1,2,a,b]]`` is mapped into the longer `[Tuple{1,2,:a,:b}]`.

### Limitations

1. For full speed, ensure that the names of the indices are fully determined at compile-time so that the appropriate code is only generated once and so that function *specialization by value* does not lead to performance degradation.

2. Single-bracket indexing is still safe - use `hcat` and `vcat` when necessary to concatenate inside expresions like `@tensor v[vcat(indices1,indices2)][[a]]`. 

3. Some operations, defined by AbstractArray, may lead to an automatic de-indexing of a `Tensor` to an `Array` - for instance, those that automatically fall back to `broadcast!()`.

### TODO / Ideas to implement

1. Labelled `eigs` and `svds`.

2. A macro for automatic loop unrolling of some indices. This will allow for (a) reducing memory requirements of some tensor network contractions and (b) multi-index contractions, e.g. `a[[i]]*b[[i]]*c[[i]]` performs `sum(a.*b.*c)` and `a[[i]] = b[[i]]*c[[i]]` is equivalent to `a = b.*c`.

3. Refine syntax